{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Input, Dense, Dropout\n",
    "# from keras.optimizers import Adam\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as  plt\n",
    "from sklearn import tree                                                        \n",
    "\n",
    "SPLIT_SEED = 1\n",
    "MENS = 'mens'\n",
    "WOMENS = 'womens'\n",
    "TEST = 'test'\n",
    "TRAIN = 'train'\n",
    "\n",
    "# Columns in Data With Categorical Values- Must LabelEncode them\n",
    "categorical_cols = ['hitpoint', 'outside.sideline', 'outside.baseline', 'same.side', \n",
    "                    'previous.hitpoint', 'server.is.impact.player', 'outcome']\n",
    "\n",
    "# Columns in the Data That Should Be Scaled\n",
    "scaled_data = ['serve', 'rally', 'speed', 'net.clearance', 'distance.from.sideline', 'depth', 'player.distance.travelled', \n",
    "               'player.impact.depth', 'player.impact.distance.from.center', 'player.depth', \n",
    "               'player.distance.from.center', 'previous.speed', 'previous.net.clearance', \n",
    "               'previous.distance.from.sideline', 'previous.depth', 'opponent.depth', \n",
    "               'opponent.distance.from.center', 'previous.time.to.net']\n",
    "               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from copy import deepcopy\n",
    "import pymysql\n",
    "\n",
    "# Load Data\n",
    "\n",
    "host = \"gtbootcamp.mysql.database.azure.com\"\n",
    "user = \"harish@gtbootcamp\"\n",
    "password = \"JsOverload!23\"\n",
    "db = \"tennis_db\"\n",
    "con = pymysql.connect(host=host, user=user, password=password, db=db, cursorclass=pymysql.cursors.\n",
    "                                   DictCursor)\n",
    "cur = con.cursor()\n",
    "mens_train = pd.read_csv('tennis_data/mens_train_file.csv')\n",
    "mens_test = pd.read_csv(\"tennis_data/mens_test_file.csv\")\n",
    "# print((mens_test.head()))\n",
    "# Encode Categorical Data\n",
    "def encode(train, test):\n",
    "    # Retain All LabelEncoder as a dictionary\n",
    "    d = defaultdict(LabelEncoder)\n",
    "\n",
    "    # Encode all the columns\n",
    "    train[categorical_cols] = train[categorical_cols].apply(lambda x: d[x.name].fit_transform(x))\n",
    "#     test[categorical_cols] = train[categorical_cols].apply(lambda x: d[x.name].fit_transform(x))\n",
    "    test_ids = test['id']\n",
    "    # Inverse the encoding\n",
    "    # data.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "    \n",
    "    # Using dictionary d to label future data\n",
    "    temp = deepcopy(categorical_cols)\n",
    "    temp.remove('outcome')\n",
    "    e = deepcopy(d)\n",
    "    del e['outcome']\n",
    "#     for key in e.keys():\n",
    "#         print(key)\n",
    "#         print(e[key].classes_)\n",
    "#     print(temp)\n",
    "    \n",
    "    test[temp] = test[temp].apply(lambda x: e[x.name].transform(x))\n",
    "# #     print(d['hitpoint'].classes_)\n",
    "    train = train.drop(['gender', 'id', 'train'], axis=1)\n",
    "    test = test.drop(['gender', 'id', 'outcome', 'train'], axis=1)\n",
    "    \n",
    "    return train, test, test_ids, d\n",
    "\n",
    "# print(train['serve'])\n",
    "mens_train, mens_test, test_ids , d = encode(mens_train, mens_test)\n",
    "# print(mens_test_X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mens_train_X, val_mens_X = train_test_split(mens_train, test_size=0.2, shuffle=True)\n",
    "X_train = mens_train_X.loc[:, mens_train_X.columns != 'outcome']\n",
    "y_train = mens_train_X['outcome']\n",
    "X_val = val_mens_X.loc[:, val_mens_X.columns != 'outcome']\n",
    "y_val = val_mens_X['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 67.0000%\n",
      "Log Loss: 5.331372859362093\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 42.7000%\n",
      "Log Loss: 0.8246950543284836\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 77.1000%\n",
      "Log Loss: 7.909379794434547\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 83.2000%\n",
      "Log Loss: 0.7518943599769671\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_val)\n",
    "    ll = log_loss(y_val, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
